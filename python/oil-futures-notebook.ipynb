{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Databento Oil Futures Data Analysis\n",
    "\n",
    "This notebook demonstrates loading and analyzing oil futures data from Databento.\n",
    "\n",
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zstandard as zstd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DabentoLoader:\n",
    "    \"\"\"Class to load and process Databento oil futures data\"\"\"\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.symbol_map = None\n",
    "        self.loaded_data = {}\n",
    "        \n",
    "    def load_symbol_mappings(self):\n",
    "        \"\"\"Load and process symbol mapping information\"\"\"\n",
    "        symbol_df = pd.read_csv(self.base_path / 'mini_symbology.csv')\n",
    "        self.symbol_map = symbol_df.groupby('raw_symbol')['instrument_id'].first().to_dict()\n",
    "        return self.symbol_map\n",
    "    \n",
    "    def decompress_zst(self, file_path):\n",
    "        \"\"\"Decompress a .zst file and return its contents\"\"\"\n",
    "        with open(file_path, 'rb') as fh:\n",
    "            dctx = zstd.ZstdDecompressor()\n",
    "            decompressed = dctx.stream_reader(fh)\n",
    "            return pd.read_csv(decompressed)\n",
    "    \n",
    "    def load_ohlcv_files(self, pattern=\"glbx-mdp3-*.ohlcv-1m.*.csv.zst\"):\n",
    "        \"\"\"Load all OHLCV files matching the pattern\"\"\"\n",
    "        files = glob.glob(str(self.base_path / pattern))\n",
    "        \n",
    "        for file in files:\n",
    "            try:\n",
    "                symbol = file.split('ohlcv-1m.')[-1].split('.csv.zst')[0]\n",
    "                df = self.decompress_zst(file)\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ns')\n",
    "                df.set_index('timestamp', inplace=True)\n",
    "                self.loaded_data[symbol] = df\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {str(e)}\")\n",
    "    \n",
    "    def create_consolidated_df(self):\n",
    "        \"\"\"Create a consolidated multi-level DataFrame\"\"\"\n",
    "        consolidated = {}\n",
    "        \n",
    "        for symbol, df in self.loaded_data.items():\n",
    "            for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "                if col not in consolidated:\n",
    "                    consolidated[col] = pd.DataFrame()\n",
    "                consolidated[col][symbol] = df[col]\n",
    "        \n",
    "        final_df = pd.concat(\n",
    "            [consolidated[col] for col in ['open', 'high', 'low', 'close', 'volume']],\n",
    "            keys=['open', 'high', 'low', 'close', 'volume'],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Set the path to your data directory and load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your data directory\n",
    "BASE_PATH = 'path/to/your/data/directory'\n",
    "\n",
    "# Initialize loader\n",
    "loader = DabentoLoader(BASE_PATH)\n",
    "\n",
    "# Load symbol mappings\n",
    "symbol_map = loader.load_symbol_mappings()\n",
    "print(f\"Loaded {len(symbol_map)} symbol mappings\")\n",
    "\n",
    "# Load OHLCV data\n",
    "loader.load_ohlcv_files()\n",
    "print(f\"Loaded data for {len(loader.loaded_data)} symbols\")\n",
    "\n",
    "# Create consolidated DataFrame\n",
    "df = loader.create_consolidated_df()\n",
    "print(f\"Created consolidated DataFrame with shape {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's examine the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Number of symbols: {len(df.columns.levels[1])}\")\n",
    "\n",
    "# Display available symbols\n",
    "print(\"\\nAvailable symbols:\")\n",
    "print(df.columns.levels[1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Visualization\n",
    "\n",
    "Let's create some basic visualizations of the futures data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_futures_prices(df, symbols=None, n_symbols=5):\n",
    "    \"\"\"Plot closing prices for selected futures contracts\"\"\"\n",
    "    if symbols is None:\n",
    "        # Take first n_symbols if none specified\n",
    "        symbols = df['close'].columns[:n_symbols]\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for symbol in symbols:\n",
    "        plt.plot(df['close'][symbol], label=symbol)\n",
    "    \n",
    "    plt.title('Futures Closing Prices')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the first 5 symbols\n",
    "plot_futures_prices(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Basic Trading Metrics\n",
    "\n",
    "Let's calculate some basic trading metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, symbol):\n",
    "    \"\"\"Calculate basic trading metrics for a symbol\"\"\"\n",
    "    # Daily returns\n",
    "    returns = df['close'][symbol].pct_change()\n",
    "    \n",
    "    # Volatility (20-day rolling)\n",
    "    volatility = returns.rolling(20).std() * np.sqrt(252)\n",
    "    \n",
    "    # 20-day moving average\n",
    "    ma20 = df['close'][symbol].rolling(20).mean()\n",
    "    \n",
    "    metrics = pd.DataFrame({\n",
    "        'returns': returns,\n",
    "        'volatility': volatility,\n",
    "        'ma20': ma20\n",
    "    })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for the first symbol\n",
    "first_symbol = df['close'].columns[0]\n",
    "metrics = calculate_metrics(df, first_symbol)\n",
    "print(f\"Metrics for {first_symbol}:\")\n",
    "print(metrics.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Potential next steps for analysis:\n",
    "1. Implement contract roll adjustment\n",
    "2. Calculate term structure and spreads\n",
    "3. Implement technical indicators\n",
    "4. Develop trading strategies\n",
    "5. Perform backtesting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
